{"metadata":{"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport os,cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\n\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers.core import Dense, Flatten\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\n#from keras.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.utils import np_utils\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\n\nK.set_image_dim_ordering('tf')\n%matplotlib inline\n\n","metadata":{"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-16fe85f80393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"],"ename":"ModuleNotFoundError","evalue":"No module named 'cv2'","output_type":"error"}]},{"cell_type":"code","source":"PATH = os.getcwd()\n# Define data path\ndata_path ='C:/Users/hasib/Downloads/Vgg16'\ndata_dir_list = os.listdir(data_path)\n\nimg_rows=224\nimg_cols=224\nnum_channel=3\nnum_epoch=50\n\n# Define the number of classes\nnum_classes = 5\n\nimg_data_list=[]\n\nfor dataset in data_dir_list:\n\timg_list=os.listdir(data_path+'/'+ dataset)\n\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n\tfor img in img_list:\n\t\tinput_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n\t\t#input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n\t\tinput_img_resize=cv2.resize(input_img,(224,224))\n\t\timg_data_list.append(input_img_resize)\n\nimg_data = np.array(img_data_list)\nimg_data = img_data.astype('float32')\nimg_data /= 255\nprint (img_data.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"USE_SKLEARN_PREPROCESSING=False\n\nif USE_SKLEARN_PREPROCESSING:\n\t# using sklearn for preprocessing\n\tfrom sklearn import preprocessing\n\t\n\tdef image_to_feature_vector(image, size=(224, 224)):\n\t\t# resize the image to a fixed size, then flatten the image into\n\t\t# a list of raw pixel intensities\n\t\treturn cv2.resize(image, size).flatten()\n\t\n\timg_data_list=[]\n\tfor dataset in data_dir_list:\n\t\timg_list=os.listdir(data_path+'/'+ dataset)\n\t\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n\t\tfor img in img_list:\n\t\t\tinput_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n\t\t\tinput_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n\t\t\tinput_img_flatten=image_to_feature_vector(input_img,(224,224))\n\t\t\timg_data_list.append(input_img_flatten)\n\t\n\timg_data = np.array(img_data_list)\n\timg_data = img_data.astype('float32')\n\tprint (img_data.shape)\n\timg_data_scaled = preprocessing.scale(img_data)\n\tprint (img_data_scaled.shape)\n\t\n\tprint (np.mean(img_data_scaled))\n\tprint (np.std(img_data_scaled))\n\t\n\tprint (img_data_scaled.mean(axis=0))\n\tprint (img_data_scaled.std(axis=0))\n\t\n\tif K.image_dim_ordering()=='th':\n\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],num_channel,img_rows,img_cols)\n\t\tprint (img_data_scaled.shape)\n\t\t\n\telse:\n\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],img_rows,img_cols,num_channel)\n\t\tprint (img_data_scaled.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if USE_SKLEARN_PREPROCESSING:\n\timg_data=img_data_scaled\n#%%\n# Assigning Labels\n\n# Define the number of classes\nnum_classes = 5\n\nnum_of_samples = img_data.shape[0]\nlabels = np.ones((num_of_samples,),dtype='int64')\n\nlabels[0:260]=0\nlabels[260:310]=1\nlabels[310:602]=2\nlabels[602:853]=3\nlabels[853:1104]=4\n\n\t  \nnames = ['Blackhead','Cysts','Papules','Pustules','Whitehead']\n\t  \n# convert class labels to on-hot encoding\nY = np_utils.to_categorical(labels, num_classes)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx,y = shuffle(img_data,Y, random_state=1)\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nvgg16_model = keras.applications.vgg16.VGG16()\nvgg16_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(vgg16_model)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nfor layer in vgg16_model.layers[:-1]:\n    model.add(layer)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in model.layers:\n    layer.trainable = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.add(Dense(num_classes,activation= 'softmax'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=[\"accuracy\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(X_train, y_train, batch_size=16, epochs=50, verbose=1, validation_data=(X_test, y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss=hist.history['loss']\nval_loss=hist.history['val_loss']\ntrain_acc=hist.history['acc']\nval_acc=hist.history['val_acc']\nxc=range(10)\n\nplt.figure(1,figsize=(7,5))\nplt.plot(xc,train_loss)\nplt.plot(xc,val_loss)\nplt.xlabel('num of Epochs')\nplt.ylabel('loss')\nplt.title('train_loss vs val_loss')\nplt.grid(True)\nplt.legend(['train','val'])\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])\n\nplt.figure(2,figsize=(7,5))\nplt.plot(xc,train_acc)\nplt.plot(xc,val_acc)\nplt.xlabel('num of Epochs')\nplt.ylabel('accuracy')\nplt.title('train_acc vs val_acc')\nplt.grid(True)\nplt.legend(['train','val'],loc=4)\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image = cv2.imread('F:/tealeaf/test/18.jpg')\ntest_image=cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\ntest_image=cv2.resize(test_image,(128,128))\ntest_image = np.array(test_image)\ntest_image = test_image.astype('float32')\ntest_image /= 255\nprint (test_image.shape)\n   \nif num_channel==1:\n\tif K.image_dim_ordering()=='th':\n\t\ttest_image= np.expand_dims(test_image, axis=0)\n\t\ttest_image= np.expand_dims(test_image, axis=0)\n\t\tprint (test_image.shape)\n\telse:\n\t\ttest_image= np.expand_dims(test_image, axis=3) \n\t\ttest_image= np.expand_dims(test_image, axis=0)\n\t\tprint (test_image.shape)\n\t\t\nelse:\n\tif K.image_dim_ordering()=='th':\n\t\ttest_image=np.rollaxis(test_image,2,0)\n\t\ttest_image= np.expand_dims(test_image, axis=0)\n\t\tprint (test_image.shape)\n\telse:\n\t\ttest_image= np.expand_dims(test_image, axis=0)\n\t\tprint (test_image.shape)\n\t\t\n# Predicting the test image\nprint((model.predict(test_image)))\nprint(model.predict_classes(test_image))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\nimport itertools\n\nY_pred = model.predict(X_test)\n#print(Y_pred)\ny_pred = np.argmax(Y_pred, axis=1)\n#print(y_pred)\n#y_pred = model.predict_classes(X_test)\n#print(y_pred)\ntarget_names = ['Blackhead','Cysts','Papules','Pustules','Whitehead']\n\nprint(confusion_matrix(np.argmax(y_test,axis=1), y_pred))\nprint(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \ncnf_matrix = (confusion_matrix(np.argmax(y_test,axis=1), y_pred))\n\nnp.set_printoptions(precision=2)\n\nplt.figure()\n\n# Plot non-normalized confusion matrix\nplot_confusion_matrix(cnf_matrix, classes=target_names,\n                      title='Confusion matrix')\n#plt.figure()\n# Plot normalized confusion matrix\n#plot_confusion_matrix(cnf_matrix, classes=target_names, normalize=True,\n#                      title='Normalized confusion matrix')\n#plt.figure()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import model_from_json\nfrom keras.models import load_model\n\n# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")\n\n# load json and create model\njson_file = open('model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")\n\nmodel.save('model.hdf5')\nloaded_model=load_model('mode1.hdf5'","metadata":{},"execution_count":null,"outputs":[]}]}